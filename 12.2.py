import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.applications import mobilenet_v2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions
from PIL import Image
import requests
from io import BytesIO

# --- å…¨å±€è®¾ç½® ---
# è®¾ç½® Matplotlib å­—ä½“ä»¥æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡å’Œè´Ÿå·
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# --- å‡½æ•°å®šä¹‰ ---

def preprocess_image_from_url(url: str, target_size: tuple = (224, 224)) -> tuple:
    """
    ä»ç»™å®šçš„URLä¸‹è½½å›¾ç‰‡ï¼Œå¹¶è¿›è¡Œé¢„å¤„ç†ä»¥é€‚é…MobileNetV2æ¨¡å‹ã€‚

    Args:
        url (str): å›¾ç‰‡çš„URLåœ°å€ã€‚
        target_size (tuple): æ¨¡å‹è¾“å…¥æ‰€éœ€çš„ç›®æ ‡å›¾ç‰‡å°ºå¯¸ã€‚

    Returns:
        tuple: åŒ…å«åŸå§‹PILå›¾ç‰‡å¯¹è±¡å’Œé¢„å¤„ç†åçš„numpyæ•°ç»„ã€‚
               å¦‚æœä¸‹è½½æˆ–å¤„ç†å¤±è´¥ï¼Œåˆ™è¿”å› (None, None)ã€‚
    """
    try:
        # ä¸‹è½½å›¾ç‰‡
        print(f"æ­£åœ¨ä»URLä¸‹è½½å›¾ç‰‡: {url}")
        response = requests.get(url)
        response.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ (å¦‚ 404), åˆ™ä¼šæŠ›å‡ºå¼‚å¸¸

        # ä»äºŒè¿›åˆ¶å†…å®¹ä¸­æ‰“å¼€å›¾ç‰‡
        original_img = Image.open(BytesIO(response.content))

        # è°ƒæ•´å›¾ç‰‡å¤§å°å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        resized_img = original_img.resize(target_size)
        img_array = image.img_to_array(resized_img)

        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ (ä»(H, W, C)å˜ä¸º(1, H, W, C))
        img_array = np.expand_dims(img_array, axis=0)

        # åº”ç”¨æ¨¡å‹ç‰¹å®šçš„é¢„å¤„ç†
        processed_img_array = preprocess_input(img_array)

        print("âœ… å›¾ç‰‡é¢„å¤„ç†å®Œæˆï¼")
        print(f"å¤„ç†åçš„å›¾ç‰‡å½¢çŠ¶: {processed_img_array.shape}")

        return original_img, processed_img_array

    except requests.exceptions.RequestException as e:
        print(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥: {e}")
        return None, None
    except Exception as e:
        print(f"âŒ å›¾ç‰‡å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None, None


def get_predictions(model, processed_img_array: np.ndarray, top: int = 3) -> list:
    """
    ä½¿ç”¨æ¨¡å‹å¯¹é¢„å¤„ç†åçš„å›¾ç‰‡è¿›è¡Œé¢„æµ‹ã€‚

    Args:
        model: é¢„è®­ç»ƒçš„Kerasæ¨¡å‹ã€‚
        processed_img_array (np.ndarray): é¢„å¤„ç†åçš„å›¾ç‰‡æ•°ç»„ã€‚
        top (int): éœ€è¦è¿”å›çš„æœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹æ•°é‡ã€‚

    Returns:
        list: è§£ç åçš„é¢„æµ‹ç»“æœåˆ—è¡¨ã€‚
    """
    print("\nâœ… AIæ¨¡å‹æ­£åœ¨åˆ†æå›¾ç‰‡...")
    predictions = model.predict(processed_img_array)
    decoded_predictions = decode_predictions(predictions, top=top)[0]

    print("ğŸ¯ AIè¯†åˆ«ç»“æœï¼š")
    print("=" * 40)
    for i, (imagenet_id, label, confidence) in enumerate(decoded_predictions):
        print(f"{i+1}. {label}: {confidence*100:.2f}% ç½®ä¿¡åº¦")
    print("=" * 40)

    return decoded_predictions


def display_results(original_img: Image.Image, predictions: list):
    """
    ä½¿ç”¨ Matplotlib å¯è§†åŒ–è¾“å…¥å›¾ç‰‡å’Œæ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚

    Args:
        original_img (Image.Image): åŸå§‹çš„PILå›¾ç‰‡å¯¹è±¡ã€‚
        predictions (list): æ¨¡å‹çš„é¢„æµ‹ç»“æœåˆ—è¡¨ã€‚
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # å­å›¾1: æ˜¾ç¤ºåŸå§‹å›¾ç‰‡
    ax1.imshow(original_img)
    ax1.set_title('è¾“å…¥å›¾ç‰‡')
    ax1.axis('off')

    # å­å›¾2: æ˜¾ç¤ºé¢„æµ‹ç»“æœçš„æ¡å½¢å›¾
    labels = [pred[1] for pred in predictions]
    confidences = [pred[2] * 100 for pred in predictions]
    colors = ['#FF9999', '#66B2FF', '#99FF99']

    bars = ax2.barh(range(len(labels)), confidences, color=colors)
    ax2.set_yticks(range(len(labels)))
    ax2.set_yticklabels(labels)
    ax2.set_xlabel('ç½®ä¿¡åº¦ (%)')
    ax2.set_title('AIè¯†åˆ«ç»“æœ')
    ax2.invert_yaxis()  # åè½¬Yè½´ï¼Œè®©æœ€é«˜ç½®ä¿¡åº¦æ˜¾ç¤ºåœ¨æœ€ä¸Šé¢

    # åœ¨æ¡å½¢å›¾ä¸Šæ·»åŠ ç½®ä¿¡åº¦æ•°å€¼
    for bar, confidence in zip(bars, confidences):
        ax2.text(bar.get_width() + 1, bar.get_y() + bar.get_height() / 2,
                 f'{confidence:.1f}%', ha='left', va='center')

    plt.tight_layout()
    plt.show()


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    print("æ­£åœ¨åŠ è½½ MobileNetV2 æ¨¡å‹...")
    model = mobilenet_v2.MobileNetV2(weights='imagenet')
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼\n")

    # 2. å®šä¹‰å›¾ç‰‡URLå¹¶è¿›è¡Œé¢„å¤„ç†
    cat_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Shiba_inu_taiki.jpg/1018px-Shiba_inu_taiki.jpg"
    original_cat_img, processed_img = preprocess_image_from_url(cat_url)

    # 3. å¦‚æœå›¾ç‰‡å¤„ç†æˆåŠŸï¼Œåˆ™è¿›è¡Œé¢„æµ‹å’Œå±•ç¤º
    if original_cat_img and processed_img is not None:
        # 4. è·å–é¢„æµ‹ç»“æœ
        top_predictions = get_predictions(model, processed_img, top=3)

        # 5. å¯è§†åŒ–ç»“æœ
        print("\nâœ… æ­£åœ¨ç”Ÿæˆç»“æœå¯è§†åŒ–å›¾è¡¨...")
        display_results(original_cat_img, top_predictions)
        print("âœ… æ“ä½œå®Œæˆï¼")

